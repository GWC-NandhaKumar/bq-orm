=== PROJECT FOLDER STRUCTURE ===

bigQueryORM.ts
dataTypes.ts
index.ts
logger.ts
model.ts
op.ts
queryInterface.ts
utils.ts


=== CODE FILES CONTENT ===


===== src\bigQueryORM.ts =====

// src/bigQueryORM.ts
import { BigQuery } from "@google-cloud/bigquery";
import * as fs from "fs";
import * as path from "path";
import { Model } from "./model";
import { DataType, DataTypes } from "./dataTypes";
import { QueryInterface } from "./queryInterface";
import { dataTypeToSchemaField } from "./utils";
import { createLogger, Logger } from "./logger";

export interface BigQueryORMConfig {
  projectId: string;
  keyFilename?: string;
  logging?: boolean;
  freeTierMode?: boolean;
}

export class BigQueryORM {
  public bigquery: BigQuery;
  public config: Required<BigQueryORMConfig>;
  public models: Record<string, typeof Model> = {};
  private queryInterface: QueryInterface;
  private executedMigrations: Set<string> = new Set();
  public logger: Logger;

  constructor(config?: Partial<BigQueryORMConfig>) {
    // Default logging to false if undefined
    const logging =
      config?.logging ?? process.env.BIGQUERY_ORM_LOGGING === "true";
    this.logger = createLogger(logging);
    this.logger.info("[BigQueryORM:constructor] Initializing BigQueryORM", {
      config,
    });

    this.config = {
      projectId: config?.projectId || process.env.GOOGLE_CLOUD_PROJECT || "",
      keyFilename:
        config?.keyFilename || process.env.GOOGLE_APPLICATION_CREDENTIALS || "",
      logging,
      freeTierMode: config?.freeTierMode ?? false,
    };

    if (!this.config.projectId) {
      this.logger.error(
        "[BigQueryORM:constructor] projectId must be provided via config or GOOGLE_CLOUD_PROJECT env"
      );
      throw new Error(
        "projectId must be provided via config or GOOGLE_CLOUD_PROJECT env."
      );
    }

    this.bigquery = new BigQuery({
      projectId: this.config.projectId,
      keyFilename: this.config.keyFilename,
    });
    this.queryInterface = new QueryInterface(this);
    this.logger.info(
      "[BigQueryORM:constructor] BigQueryORM initialized successfully"
    );
  }

  async createDataset(
    dataset: string,
    options: { location?: string; labels?: Record<string, string> } = {}
  ): Promise<void> {
    this.logger.info("[BigQueryORM:createDataset] Starting dataset creation", {
      dataset,
      options,
    });
    if (!dataset) {
      this.logger.error(
        "[BigQueryORM:createDataset] Dataset name must be provided"
      );
      throw new Error("Dataset name must be provided");
    }

    const ds = this.bigquery.dataset(dataset);
    const [dsExists] = await ds.exists();
    if (dsExists) {
      this.logger.info(
        `[BigQueryORM:createDataset] Dataset ${dataset} already exists, skipping creation`
      );
      return;
    }

    try {
      await ds.create({
        location: options.location,
        labels: options.labels,
      });
      this.logger.info(
        `[BigQueryORM:createDataset] Created dataset ${dataset}`,
        options
      );
    } catch (err: any) {
      this.logger.error(
        `[BigQueryORM:createDataset] Failed to create dataset ${dataset}:`,
        err.message
      );
      throw err;
    }
  }

  async authenticate(): Promise<void> {
    this.logger.info("[BigQueryORM:authenticate] Starting authentication");
    if (this.config.freeTierMode) {
      this.logger.warn(
        "[BigQueryORM:authenticate] Free tier mode: Limited to SELECT queries within 1TB limit."
      );
    }
    try {
      await this.bigquery.getDatasets({ maxResults: 1 });
      this.logger.info("[BigQueryORM:authenticate] Authentication successful");
    } catch (err: any) {
      this.logger.error(
        "[BigQueryORM:authenticate] Authentication failed:",
        err.message
      );
      throw err;
    }
  }

  define(
    name: string,
    attributes: Record<string, DataType>,
    options: { tableName?: string; primaryKey?: string } = {}
  ): typeof Model {
    this.logger.info("[BigQueryORM:define] Defining model", {
      name,
      attributes: Object.keys(attributes),
      options,
    });
    class DynamicModel extends Model {}
    DynamicModel.init(attributes, {
      orm: this,
      tableName: options.tableName,
      primaryKey: options.primaryKey,
    });
    this.models[name] = DynamicModel;
    this.logger.info("[BigQueryORM:define] Model defined successfully", {
      name,
    });
    return DynamicModel;
  }

  async loadModels(modelsPath: string): Promise<void> {
    this.logger.info(
      "[BigQueryORM:loadModels] Starting to load models from path",
      { modelsPath }
    );
    try {
      const files = fs
        .readdirSync(modelsPath)
        .filter(
          (f) =>
            !f.endsWith(".d.ts") && (f.endsWith(".ts") || f.endsWith(".js"))
        );
      this.logger.info("[BigQueryORM:loadModels] Found files", { files });

      for (const file of files) {
        const modelFunc = (await import(path.resolve(modelsPath, file)))
          .default;
        if (typeof modelFunc === "function") {
          modelFunc(this, DataTypes);
          this.logger.info("[BigQueryORM:loadModels] Loaded model from file", {
            file,
          });
        } else {
          this.logger.warn(
            "[BigQueryORM:loadModels] Invalid model file, expected a function",
            { file }
          );
        }
      }

      for (const model of Object.values(this.models)) {
        if (typeof (model as any).associate === "function") {
          (model as any).associate(this.models);
          this.logger.info("[BigQueryORM:loadModels] Associated model", {
            modelName: model.name,
          });
        } else {
          this.logger.info(
            "[BigQueryORM:loadModels] No associate function for model",
            { modelName: model.name }
          );
        }
      }
      this.logger.info(
        "[BigQueryORM:loadModels] All models loaded and associated"
      );
    } catch (err: any) {
      this.logger.error(
        "[BigQueryORM:loadModels] Failed to load models:",
        err.message
      );
      throw err;
    }
  }

  async sync(
    dataset: string,
    options: { force?: boolean; alter?: boolean } = {}
  ): Promise<void> {
    this.logger.info("[BigQueryORM:sync] Starting sync", { dataset, options });
    const { force = false, alter = false } = options;
    if (this.config.freeTierMode && (force || alter)) {
      this.logger.warn(
        "[BigQueryORM:sync] Free tier mode: Table creation/deletion may incur storage costs."
      );
    }

    const ds = this.bigquery.dataset(dataset);
    const [dsExists] = await ds.exists();
    if (!dsExists) {
      await ds.create();
      this.logger.info(`[BigQueryORM:sync] Created dataset ${dataset}`);
    }

    for (const model of Object.values(this.models)) {
      const table = ds.table(model.tableName);
      const [tExists] = await table.exists();
      if (tExists && force) {
        await table.delete();
        this.logger.info(
          `[BigQueryORM:sync] Deleted table ${model.tableName} in dataset ${dataset}`
        );
      }
      if (!tExists || force) {
        const schema = Object.entries(model.attributes).map(([name, type]) =>
          dataTypeToSchemaField(name, type)
        );
        const createOptions: any = { schema };
        // Add clustering for primary key to optimize queries (BigQuery's equivalent to indexing)
        if (model.primaryKey) {
          createOptions.clustering = { fields: [model.primaryKey] };
          this.logger.info(
            `[BigQueryORM:sync] Clustering table ${model.tableName} by primary key ${model.primaryKey} in dataset ${dataset}`
          );
        }
        await table.create(createOptions);
        this.logger.info(
          `[BigQueryORM:sync] Created table ${model.tableName} in dataset ${dataset}`
        );
      } else if (alter) {
        this.logger.warn(
          "[BigQueryORM:sync] Alter sync not supported in free tier; manual migration recommended."
        );
      }
    }
  }

  getQueryInterface(): QueryInterface {
    this.logger.info(
      "[BigQueryORM:getQueryInterface] Returning query interface"
    );
    return this.queryInterface;
  }

  async runMigrations(dataset: string, migrationsPath: string): Promise<void> {
    this.logger.info("[BigQueryORM:runMigrations] Starting migrations", {
      dataset,
      migrationsPath,
    });
    if (this.config.freeTierMode) {
      this.logger.warn(
        "[BigQueryORM:runMigrations] Free tier mode: Migrations use in-memory tracking."
      );
    }

    const ds = this.bigquery.dataset(dataset);
    let [dsExists] = await ds.exists();
    if (!dsExists) {
      await ds.create();
      this.logger.info(
        `[BigQueryORM:runMigrations] Created dataset ${dataset}`
      );
    }

    const metaTable = ds.table("migrations");
    let [tExists] = await metaTable.exists();
    if (!tExists && !this.config.freeTierMode) {
      await metaTable.create({
        schema: [
          { name: "name", type: "STRING" },
          { name: "executed_at", type: "TIMESTAMP" },
        ],
      });
      this.logger.info(
        "[BigQueryORM:runMigrations] Created migrations table in dataset ${dataset}"
      );
    }

    let executed: Set<string>;
    if (this.config.freeTierMode) {
      executed = this.executedMigrations;
      this.logger.info(
        "[BigQueryORM:runMigrations] Using in-memory executed migrations for free tier"
      );
    } else {
      const [rows] = await this.bigquery.query({
        query: `SELECT name FROM \`${this.config.projectId}.${dataset}.migrations\` ORDER BY executed_at ASC`,
      });
      executed = new Set(rows.map((r: any) => r.name));
      this.logger.info(
        "[BigQueryORM:runMigrations] Fetched executed migrations",
        { count: executed.size }
      );
    }

    const migrationFiles = fs
      .readdirSync(migrationsPath)
      .filter(
        (f) => !f.endsWith(".d.ts") && (f.endsWith(".ts") || f.endsWith(".js"))
      )
      .sort();
    this.logger.info("[BigQueryORM:runMigrations] Found migration files", {
      files: migrationFiles,
    });

    for (const file of migrationFiles) {
      const migrationName = path.basename(file, path.extname(file));
      if (executed.has(migrationName)) {
        this.logger.info(
          `[BigQueryORM:runMigrations] Skipping migration ${migrationName} (already executed)`
        );
        continue;
      }

      const migrationModule = await import(path.resolve(migrationsPath, file));
      const migration = migrationModule.default || migrationModule;
      await migration.up(this.queryInterface, this, dataset);
      if (this.config.freeTierMode) {
        this.executedMigrations.add(migrationName);
        this.logger.info(
          `[BigQueryORM:runMigrations] Migration ${migrationName} tracked in-memory`
        );
      } else {
        const sql = `INSERT INTO \`${this.config.projectId}.${dataset}.migrations\` (name, executed_at) VALUES (@name, @executed_at)`;
        await this.bigquery.query({
          query: sql,
          params: {
            name: migrationName,
            executed_at: new Date().toISOString(),
          },
        });
        this.logger.info(
          `[BigQueryORM:runMigrations] Migration ${migrationName} executed and recorded in dataset ${dataset}`
        );
      }
    }
  }

  async revertLastMigration(
    dataset: string,
    migrationsPath: string
  ): Promise<void> {
    this.logger.info(
      "[BigQueryORM:revertLastMigration] Starting revert last migration",
      { dataset, migrationsPath }
    );
    if (this.config.freeTierMode) {
      this.logger.warn(
        "[BigQueryORM:revertLastMigration] Free tier mode: Reverting migrations not supported."
      );
      return;
    }

    const metaTable = this.bigquery.dataset(dataset).table("migrations");
    const [rows] = await this.bigquery.query({
      query: `SELECT name FROM \`${this.config.projectId}.${dataset}.migrations\` ORDER BY executed_at DESC LIMIT 1`,
    });
    if (!rows.length) {
      this.logger.info(
        "[BigQueryORM:revertLastMigration] No migrations to revert"
      );
      return;
    }
    const migrationName = rows[0].name;

    const migrationFiles = fs
      .readdirSync(migrationsPath)
      .filter(
        (f) => !f.endsWith(".d.ts") && (f.endsWith(".ts") || f.endsWith(".js"))
      );
    const migrationFile = migrationFiles.find(
      (f) => path.basename(f, path.extname(f)) === migrationName
    );
    if (!migrationFile) {
      this.logger.error(
        "[BigQueryORM:revertLastMigration] Migration file not found",
        { migrationName }
      );
      throw new Error(`Migration file not found: ${migrationName}`);
    }

    const migrationModule = await import(
      path.resolve(migrationsPath, migrationFile)
    );
    const migration = migrationModule.default || migrationModule;
    await migration.down(this.queryInterface, this, dataset);
    const sql = `DELETE FROM \`${this.config.projectId}.${dataset}.migrations\` WHERE name = @migrationName`;
    await this.bigquery.query({ query: sql, params: { migrationName } });
    this.logger.info(
      `[BigQueryORM:revertLastMigration] Reverted migration ${migrationName} in dataset ${dataset}`
    );
  }

  async transaction(
    dataset: string,
    fn: (qi: QueryInterface, dataset: string) => Promise<void>
  ): Promise<void> {
    this.logger.info("[BigQueryORM:transaction] Starting transaction", {
      dataset,
    });
    if (this.config.freeTierMode) {
      this.logger.warn(
        "[BigQueryORM:transaction] Free tier mode: Transactions limited to SELECT queries."
      );
    }
    try {
      await fn(this.queryInterface, dataset);
      this.logger.info("[BigQueryORM:transaction] Transaction successful");
    } catch (err: any) {
      this.logger.error(
        "[BigQueryORM:transaction] Transaction failed:",
        err.message
      );
      throw err;
    }
  }
}


===== src\dataTypes.ts =====

// src/dataTypes.ts
import * as crypto from "crypto";

export interface DataTypeAttribute {
  type: string;
  allowNull?: boolean;
  defaultValue?: any;
  primaryKey?: boolean;
  mode?: "REPEATED";
  fields?: Record<string, DataTypeAttribute>;
  precision?: number;
  scale?: number;
}

export type DataType = DataTypeAttribute;

export interface DataTypes {
  STRING: (options?: Partial<DataTypeAttribute>) => DataType;
  CHAR: (options?: Partial<DataTypeAttribute>) => DataType;
  TEXT: (options?: Partial<DataTypeAttribute>) => DataType;
  INTEGER: (options?: Partial<DataTypeAttribute>) => DataType;
  TINYINT: (options?: Partial<DataTypeAttribute>) => DataType;
  SMALLINT: (options?: Partial<DataTypeAttribute>) => DataType;
  MEDIUMINT: (options?: Partial<DataTypeAttribute>) => DataType;
  BIGINT: (options?: Partial<DataTypeAttribute>) => DataType;
  FLOAT: (options?: Partial<DataTypeAttribute>) => DataType;
  DOUBLE: (options?: Partial<DataTypeAttribute>) => DataType;
  DECIMAL: (
    precision: number,
    scale: number,
    options?: Partial<DataTypeAttribute>
  ) => DataType;
  BOOLEAN: (options?: Partial<DataTypeAttribute>) => DataType;
  DATE: (options?: Partial<DataTypeAttribute>) => DataType;
  DATEONLY: (options?: Partial<DataTypeAttribute>) => DataType;
  TIME: (options?: Partial<DataTypeAttribute>) => DataType;
  DATETIME: (options?: Partial<DataTypeAttribute>) => DataType;
  JSON: (options?: Partial<DataTypeAttribute>) => DataType;
  JSONB: (options?: Partial<DataTypeAttribute>) => DataType;
  BLOB: (options?: Partial<DataTypeAttribute>) => DataType;
  UUID: (options?: Partial<DataTypeAttribute>) => DataType;
  ARRAY: (itemType: DataType) => DataType;
  STRUCT: (
    fields: Record<string, DataType>,
    options?: Partial<DataTypeAttribute>
  ) => DataType;
  GEOGRAPHY: (options?: Partial<DataTypeAttribute>) => DataType;
  INTERVAL: (options?: Partial<DataTypeAttribute>) => DataType;
  BYTES: (options?: Partial<DataTypeAttribute>) => DataType;
  NOW: string;
  UUIDV4: string;
}

export const DataTypes: DataTypes = {
  STRING: (options = {}) => ({ type: "STRING", allowNull: true, ...options }),
  CHAR: (options = {}) => ({ type: "STRING", allowNull: true, ...options }),
  TEXT: (options = {}) => ({ type: "STRING", allowNull: true, ...options }),
  INTEGER: (options = {}) => ({ type: "INT64", allowNull: true, ...options }),
  TINYINT: (options = {}) => ({ type: "INT64", allowNull: true, ...options }),
  SMALLINT: (options = {}) => ({ type: "INT64", allowNull: true, ...options }),
  MEDIUMINT: (options = {}) => ({ type: "INT64", allowNull: true, ...options }),
  BIGINT: (options = {}) => ({ type: "INT64", allowNull: true, ...options }),
  FLOAT: (options = {}) => ({ type: "FLOAT64", allowNull: true, ...options }),
  DOUBLE: (options = {}) => ({ type: "FLOAT64", allowNull: true, ...options }),
  DECIMAL: (precision: number, scale: number, options = {}) => ({
    type: "NUMERIC",
    precision,
    scale,
    allowNull: true,
    ...options,
  }),
  BOOLEAN: (options = {}) => ({ type: "BOOL", allowNull: true, ...options }),
  DATE: (options = {}) => ({ type: "TIMESTAMP", allowNull: true, ...options }),
  DATEONLY: (options = {}) => ({ type: "DATE", allowNull: true, ...options }),
  TIME: (options = {}) => ({ type: "TIME", allowNull: true, ...options }),
  DATETIME: (options = {}) => ({
    type: "DATETIME",
    allowNull: true,
    ...options,
  }),
  JSON: (options = {}) => ({ type: "JSON", allowNull: true, ...options }),
  JSONB: (options = {}) => ({ type: "JSON", allowNull: true, ...options }),
  BLOB: (options = {}) => ({ type: "BYTES", allowNull: true, ...options }),
  UUID: (options = {}) => ({ type: "STRING", allowNull: true, ...options }),
  ARRAY: (itemType: DataType) => ({ ...itemType, mode: "REPEATED" }),
  STRUCT: (fields: Record<string, DataType>, options = {}) => ({
    type: "STRUCT",
    fields,
    allowNull: true,
    ...options,
  }),
  GEOGRAPHY: (options = {}) => ({
    type: "GEOGRAPHY",
    allowNull: true,
    ...options,
  }),
  INTERVAL: (options = {}) => ({
    type: "INTERVAL",
    allowNull: true,
    ...options,
  }),
  BYTES: (options = {}) => ({ type: "BYTES", allowNull: true, ...options }),
  NOW: "CURRENT_TIMESTAMP()",
  UUIDV4: "GENERATE_UUID()",
};


===== src\index.ts =====

// src/index.ts
export * from "./bigQueryORM";
export * from "./dataTypes";
export * from "./model";
export * from "./op";
export * from "./queryInterface";
export * from "./utils";
export * from "./logger";


===== src\logger.ts =====

// src/logger.ts
export interface Logger {
  info(message: string, ...args: any[]): void;
  warn(message: string, ...args: any[]): void;
  error(message: string, ...args: any[]): void;
}

export class ConsoleLogger implements Logger {
  info(message: string, ...args: any[]): void {
    console.log(`[INFO] ${message}`, ...args);
  }

  warn(message: string, ...args: any[]): void {
    console.warn(`[WARN] ${message}`, ...args);
  }

  error(message: string, ...args: any[]): void {
    console.error(`[ERROR] ${message}`, ...args);
  }
}

export class NoopLogger implements Logger {
  info(): void {}
  warn(): void {}
  error(): void {}
}

export function createLogger(enabled: boolean | undefined): Logger {
  return enabled ? new ConsoleLogger() : new NoopLogger();
}


===== src\model.ts =====

// src/model.ts
import { BigQuery } from "@google-cloud/bigquery";
import { BigQueryORM } from "./bigQueryORM";
import { Op, Operator } from "./op";
import { DataType, DataTypes } from "./dataTypes";
import { buildWhereClause } from "./utils";
import * as crypto from "crypto";

export interface WhereOptions {
  [key: string]: any | { [key in Operator]?: any } | WhereOptions[];
}

export interface IncludeOptions {
  model: typeof Model;
  as?: string;
  where?: WhereOptions;
  required?: boolean;
  attributes?: string[];
}

export interface FindOptions {
  attributes?: string[];
  where?: WhereOptions;
  include?: IncludeOptions[];
  order?: [string, "ASC" | "DESC"][];
  group?: string[];
  limit?: number;
  offset?: number;
  raw?: boolean;
  distinct?: boolean;
}

export interface Association {
  type: "hasOne" | "hasMany" | "belongsTo" | "belongsToMany";
  target: typeof Model;
  foreignKey: string;
  otherKey?: string;
  as?: string;
  through?: typeof Model;
}

export interface FindAndCountAllResult {
  rows: any[];
  count: number;
}

export interface BulkCreateOptions {
  validate?: boolean;
  ignoreDuplicates?: boolean;
  returning?: boolean;
}

export interface UpdateOptions {
  where: WhereOptions;
  returning?: boolean;
  individualHooks?: boolean;
}

export interface DestroyOptions {
  where: WhereOptions;
  force?: boolean;
  cascade?: boolean;
}

export abstract class Model {
  static orm: BigQueryORM;
  static tableName: string;
  static primaryKey: string = "id";
  static attributes: Record<string, DataType>;
  static associations: Record<string, Association> = {};
  static associate?: (models: Record<string, typeof Model>) => void;

  static init(
    attributes: Record<string, DataType>,
    options: { orm: BigQueryORM; tableName?: string; primaryKey?: string }
  ) {
    this.orm = options.orm;
    this.orm.logger.info(
      `[Model:init] Starting initialization for model: ${this.name}`
    );
    this.attributes = attributes;
    this.tableName = options.tableName || this.name.toLowerCase();
    this.primaryKey =
      options.primaryKey ||
      Object.keys(attributes).find((key) => attributes[key].primaryKey) ||
      "id";
    this.orm.logger.info(
      `[Model:init] Initialization complete for model: ${this.name}`
    );
  }

  static belongsTo(
    target: typeof Model,
    options: { foreignKey?: string; as?: string } = {}
  ) {
    const foreignKey = options.foreignKey || `${target.name.toLowerCase()}Id`;
    const as = options.as || target.name.toLowerCase();
    this.associations[as] = { type: "belongsTo", target, foreignKey, as };
    if (!this.attributes[foreignKey]) {
      this.attributes[foreignKey] = DataTypes.INTEGER();
    }
    this.orm.logger.info(
      `[Model:belongsTo] Set up belongsTo ${this.name} -> ${target.name}`
    );
  }

  static hasOne(
    target: typeof Model,
    options: { foreignKey?: string; as?: string } = {}
  ) {
    const foreignKey = options.foreignKey || `${this.name.toLowerCase()}Id`;
    const as = options.as || target.name.toLowerCase();
    this.associations[as] = { type: "hasOne", target, foreignKey, as };
    this.orm.logger.info(
      `[Model:hasOne] Set up hasOne ${this.name} -> ${target.name}`
    );
  }

  static hasMany(
    target: typeof Model,
    options: { foreignKey?: string; as?: string } = {}
  ) {
    const foreignKey = options.foreignKey || `${this.name.toLowerCase()}Id`;
    const as = options.as || `${target.name.toLowerCase()}s`;
    this.associations[as] = { type: "hasMany", target, foreignKey, as };
    this.orm.logger.info(
      `[Model:hasMany] Set up hasMany ${this.name} -> ${target.name}`
    );
  }

  static belongsToMany(
    target: typeof Model,
    options: {
      through: typeof Model;
      foreignKey?: string;
      otherKey?: string;
      as?: string;
    }
  ) {
    const foreignKey = options.foreignKey || `${this.name.toLowerCase()}Id`;
    const otherKey = options.otherKey || `${target.name.toLowerCase()}Id`;
    const as = options.as || `${target.name.toLowerCase()}s`;
    this.associations[as] = {
      type: "belongsToMany",
      target,
      foreignKey,
      otherKey,
      through: options.through,
      as,
    };
    this.orm.logger.info(
      `[Model:belongsToMany] Set up belongsToMany ${this.name} -> ${target.name}`
    );
  }

  static async findAll(
    dataset: string,
    options: FindOptions = {}
  ): Promise<any[]> {
    const { sql, params } = this.buildSelectQuery(dataset, options);
    this.orm.logger.info(
      `[Model:findAll] Executing query for ${this.name} in dataset ${dataset}`,
      {
        sql,
        params,
      }
    );
    const [rows] = await this.orm.bigquery.query({ query: sql, params });
    const result = options.raw
      ? rows
      : this.nestAssociations(rows, options.include || []);
    this.orm.logger.info(
      `[Model:findAll] Found ${result.length} records for ${this.name} in dataset ${dataset}`
    );
    return result;
  }

  static async findOne(
    dataset: string,
    options: FindOptions = {}
  ): Promise<any | null> {
    this.orm.logger.info(
      `[Model:findOne] Finding one record for ${this.name} in dataset ${dataset}`,
      { options }
    );
    const results = await this.findAll(dataset, { ...options, limit: 1 });
    const result = results[0] || null;
    this.orm.logger.info(
      `[Model:findOne] Found record: ${result ? "yes" : "no"} for ${
        this.name
      } in dataset ${dataset}`
    );
    return result;
  }

  static async findByPk(
    dataset: string,
    pk: any,
    options: FindOptions = {}
  ): Promise<any | null> {
    this.orm.logger.info(
      `[Model:findByPk] Finding by PK for ${this.name} in dataset ${dataset}`,
      {
        pk,
        options,
      }
    );
    return this.findOne(dataset, {
      ...options,
      where: { [this.primaryKey]: pk },
    });
  }

  static async findAndCountAll(
    dataset: string,
    options: FindOptions = {}
  ): Promise<FindAndCountAllResult> {
    this.orm.logger.info(
      `[Model:findAndCountAll] Finding and counting records for ${this.name} in dataset ${dataset}`,
      { options }
    );

    const mainAlias = this.tableName;
    const selectClause: string[] = [];
    const params: Record<string, any> = {};
    let sql = `FROM \`${dataset}.${this.tableName}\` AS \`${mainAlias}\``;
    const whereClauses: string[] = [];

    // Build select clause for rows
    const mainAttributes = options.attributes || Object.keys(this.attributes);
    for (const field of mainAttributes) {
      selectClause.push(
        `\`${mainAlias}\`.\`${field}\` AS \`${mainAlias}_${field}\``
      );
    }

    // Handle includes (associations)
    if (options.include) {
      for (const inc of options.include) {
        const as = inc.as || inc.model.tableName;
        const assoc = Object.values(this.associations).find(
          (a) => a.as === as && a.target === inc.model
        );
        if (!assoc) {
          this.orm.logger.error(
            `[Model:findAndCountAll] Association not found for ${inc.model.name} in ${this.name}`
          );
          throw new Error(`Association not found for ${inc.model.name}`);
        }
        const joinType = inc.required ? "INNER JOIN" : "LEFT OUTER JOIN";
        let joinOn: string;
        if (assoc.type === "belongsTo") {
          joinOn = `\`${mainAlias}\`.\`${assoc.foreignKey}\` = \`${as}\`.\`${inc.model.primaryKey}\``;
          sql += ` ${joinType} \`${dataset}.${inc.model.tableName}\` AS \`${as}\` ON ${joinOn}`;
        } else if (assoc.type === "hasOne" || assoc.type === "hasMany") {
          joinOn = `\`${mainAlias}\`.\`${this.primaryKey}\` = \`${as}\`.\`${assoc.foreignKey}\``;
          sql += ` ${joinType} \`${dataset}.${inc.model.tableName}\` AS \`${as}\` ON ${joinOn}`;
        } else if (assoc.type === "belongsToMany") {
          if (!assoc.through || !assoc.otherKey) {
            this.orm.logger.error(
              `[Model:findAndCountAll] Through model and otherKey required for belongsToMany in ${this.name}`
            );
            throw new Error(
              "Through model and otherKey required for belongsToMany"
            );
          }
          const throughAs = `${as}_through`;
          const throughTable = assoc.through.tableName;
          sql += ` ${joinType} \`${dataset}.${throughTable}\` AS \`${throughAs}\` ON \`${mainAlias}\`.\`${this.primaryKey}\` = \`${throughAs}\`.\`${assoc.foreignKey}\``;
          joinOn = `\`${throughAs}\`.\`${assoc.otherKey}\` = \`${as}\`.\`${inc.model.primaryKey}\``;
          sql += ` ${joinType} \`${dataset}.${inc.model.tableName}\` AS \`${as}\` ON ${joinOn}`;
        }

        if (inc.where) {
          const { clause, params: incParams } = buildWhereClause(inc.where);
          const prefixedClause = clause.replace(/`([^`]+)`/g, `\`${as}\`.$1`);
          whereClauses.push(prefixedClause);
          Object.assign(params, incParams);
        }

        // Add included model attributes
        const incAttributes =
          inc.attributes || Object.keys(inc.model.attributes);
        for (const field of incAttributes) {
          selectClause.push(`\`${as}\`.\`${field}\` AS \`${as}_${field}\``);
        }
      }
    }

    // Handle where conditions
    let mainWhere = "";
    if (options.where) {
      const { clause, params: mParams } = buildWhereClause(options.where);
      mainWhere = clause;
      Object.assign(params, mParams);
    }

    let whereClause = [mainWhere, ...whereClauses]
      .filter((c) => c)
      .join(" AND ");
    if (whereClause) {
      sql += ` WHERE ${whereClause}`;
    }

    // Build count subquery
    const countSelect = options.distinct
      ? `COUNT(DISTINCT \`${mainAlias}\`.\`${this.primaryKey}\`)`
      : `COUNT(*)`;
    let countSql = `SELECT ${countSelect} AS total_count FROM \`${dataset}.${this.tableName}\` AS \`${mainAlias}\``;
    if (whereClause) {
      countSql += ` WHERE ${whereClause}`;
    }

    // Combine queries using a CTE
    let finalSql = `
    WITH count_query AS (${countSql}),
         data_query AS (
           SELECT ${options.distinct ? "DISTINCT" : ""} ${selectClause.join(
      ", "
    )}
           ${sql}
           ${
             options.group
               ? `GROUP BY ${options.group.map((g) => `\`${g}\``).join(", ")}`
               : ""
           }
           ${
             options.order
               ? `ORDER BY ${options.order
                   .map(([field, dir]) => `\`${field}\` ${dir}`)
                   .join(", ")}`
               : ""
           }
           ${options.limit ? `LIMIT ${options.limit}` : ""}
           ${options.offset ? `OFFSET ${options.offset}` : ""}
         )
    SELECT data_query.*, (SELECT total_count FROM count_query) AS total_count
    FROM data_query
  `;

    // Execute query
    const [rows] = await this.orm.bigquery.query({ query: finalSql, params });
    const resultRows = options.raw
      ? rows
      : this.nestAssociations(rows, options.include || []);

    const count = rows[0]?.total_count || 0;

    this.orm.logger.info(
      `[Model:findAndCountAll] Found ${resultRows.length} rows with total count ${count} for ${this.name} in dataset ${dataset}`
    );

    return { rows: resultRows, count };
  }

  static async count(
    dataset: string,
    options: FindOptions = {}
  ): Promise<number> {
    this.orm.logger.info(
      `[Model:count] Counting records for ${this.name} in dataset ${dataset}`,
      {
        options,
      }
    );
    const select = `COUNT(DISTINCT \`${this.tableName}\`.\`${this.primaryKey}\`) AS count`;
    const { sql, params } = this.buildSelectQuery(dataset, options, select);
    const [rows] = await this.orm.bigquery.query({ query: sql, params });
    const count = rows[0]?.count || 0;
    this.orm.logger.info(
      `[Model:count] Counted ${count} records for ${this.name} in dataset ${dataset}`
    );
    return count;
  }

  static async max(
    dataset: string,
    field: string,
    options: FindOptions = {}
  ): Promise<number | null> {
    this.orm.logger.info(
      `[Model:max] Getting max value for field ${field} in ${this.name} in dataset ${dataset}`,
      {
        field,
        options,
      }
    );
    const select = `MAX(\`${this.tableName}\`.\`${field}\`) AS max_value`;
    const { sql, params } = this.buildSelectQuery(dataset, options, select);
    const [rows] = await this.orm.bigquery.query({ query: sql, params });
    const maxValue = rows[0]?.max_value || null;
    this.orm.logger.info(
      `[Model:max] Max value for ${field}: ${maxValue} in ${this.name} in dataset ${dataset}`
    );
    return maxValue;
  }

  static async min(
    dataset: string,
    field: string,
    options: FindOptions = {}
  ): Promise<number | null> {
    this.orm.logger.info(
      `[Model:min] Getting min value for field ${field} in ${this.name} in dataset ${dataset}`,
      {
        field,
        options,
      }
    );
    const select = `MIN(\`${this.tableName}\`.\`${field}\`) AS min_value`;
    const { sql, params } = this.buildSelectQuery(dataset, options, select);
    const [rows] = await this.orm.bigquery.query({ query: sql, params });
    const minValue = rows[0]?.min_value || null;
    this.orm.logger.info(
      `[Model:min] Min value for ${field}: ${minValue} in ${this.name} in dataset ${dataset}`
    );
    return minValue;
  }

  static async sum(
    dataset: string,
    field: string,
    options: FindOptions = {}
  ): Promise<number> {
    this.orm.logger.info(
      `[Model:sum] Getting sum for field ${field} in ${this.name} in dataset ${dataset}`,
      {
        field,
        options,
      }
    );
    const select = `SUM(\`${this.tableName}\`.\`${field}\`) AS sum_value`;
    const { sql, params } = this.buildSelectQuery(dataset, options, select);
    const [rows] = await this.orm.bigquery.query({ query: sql, params });
    const sumValue = rows[0]?.sum_value || 0;
    this.orm.logger.info(
      `[Model:sum] Sum for ${field}: ${sumValue} in ${this.name} in dataset ${dataset}`
    );
    return sumValue;
  }

  static async average(
    dataset: string,
    field: string,
    options: FindOptions = {}
  ): Promise<number | null> {
    this.orm.logger.info(
      `[Model:average] Getting average for field ${field} in ${this.name} in dataset ${dataset}`,
      {
        field,
        options,
      }
    );
    const select = `AVG(\`${this.tableName}\`.\`${field}\`) AS avg_value`;
    const { sql, params } = this.buildSelectQuery(dataset, options, select);
    const [rows] = await this.orm.bigquery.query({ query: sql, params });
    const avgValue = rows[0]?.avg_value || null;
    this.orm.logger.info(
      `[Model:average] Average for ${field}: ${avgValue} in ${this.name} in dataset ${dataset}`
    );
    return avgValue;
  }

  private static resolveDefault(value: any): any {
    if (value === DataTypes.NOW || value === "CURRENT_TIMESTAMP()") {
      return new Date();
    } else if (value === DataTypes.UUIDV4 || value === "GENERATE_UUID()") {
      return crypto.randomUUID();
    }
    return value;
  }

  static async create(
    dataset: string,
    data: Record<string, any>
  ): Promise<any> {
    this.orm.logger.info(
      `[Model:create] Creating record for ${this.name} in dataset ${dataset}`,
      {
        data,
      }
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[Model:create] Free tier mode: CREATE (INSERT) not allowed."
      );
      throw new Error("Free tier mode: CREATE (INSERT) not allowed.");
    }
    const filledData: Record<string, any> = {};
    for (const [field, attr] of Object.entries(this.attributes)) {
      if (field in data) {
        filledData[field] = data[field];
      } else if (attr.defaultValue !== undefined) {
        filledData[field] = this.resolveDefault(attr.defaultValue);
      } else if (attr.allowNull === false) {
        this.orm.logger.error(
          `[Model:create] Missing required field ${field} for ${this.name} in dataset ${dataset}`
        );
        throw new Error(`Missing required field ${field}`);
      }
    }
    const table = this.orm.bigquery.dataset(dataset).table(this.tableName);
    await table.insert([filledData]);
    this.orm.logger.info(
      `[Model:create] Record created for ${this.name} in dataset ${dataset}`
    );
    return filledData;
  }

  static async bulkCreate(
    dataset: string,
    data: Record<string, any>[],
    options: BulkCreateOptions = {}
  ): Promise<any[]> {
    this.orm.logger.info(
      `[Model:bulkCreate] Creating ${data.length} records for ${this.name} in dataset ${dataset}`
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[Model:bulkCreate] Free tier mode: BULK CREATE (INSERT) not allowed."
      );
      throw new Error("Free tier mode: BULK CREATE (INSERT) not allowed.");
    }
    if (!data.length) {
      this.orm.logger.info("[Model:bulkCreate] No records to create, skipping");
      return [];
    }
    const filledData = data.map((record) => {
      const filled: Record<string, any> = {};
      for (const [field, attr] of Object.entries(this.attributes)) {
        if (field in record) {
          filled[field] = record[field];
        } else if (attr.defaultValue !== undefined) {
          filled[field] = this.resolveDefault(attr.defaultValue);
        } else if (attr.allowNull === false && options.validate !== false) {
          this.orm.logger.error(
            `[Model:bulkCreate] Missing required field ${field} in bulk create record for ${this.name} in dataset ${dataset}`
          );
          throw new Error(
            `Missing required field ${field} in bulk create record`
          );
        }
      }
      return filled;
    });
    const table = this.orm.bigquery.dataset(dataset).table(this.tableName);
    await table.insert(filledData);
    this.orm.logger.info(
      `[Model:bulkCreate] ${filledData.length} records created for ${this.name} in dataset ${dataset}`
    );
    return options.returning ? filledData : [];
  }

  static async update(
    dataset: string,
    data: Record<string, any>,
    options: UpdateOptions
  ): Promise<number> {
    this.orm.logger.info(
      `[Model:update] Updating records for ${this.name} in dataset ${dataset}`,
      {
        data,
        options,
      }
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[Model:update] Free tier mode: UPDATE not allowed."
      );
      throw new Error("Free tier mode: UPDATE not allowed.");
    }
    const setClauses = Object.entries(data)
      .map(([field]) => `\`${field}\` = @set_${field}`)
      .join(", ");
    const setValues = Object.entries(data).reduce(
      (acc, [field, value]) => ({ ...acc, [`set_${field}`]: value }),
      {}
    );
    const { clause: whereClause, params: whereValues } = buildWhereClause(
      options.where
    );
    const sql = `UPDATE \`${dataset}.${
      this.tableName
    }\` SET ${setClauses} WHERE ${whereClause || "TRUE"}`;
    const allParams = { ...setValues, ...whereValues };
    const [job] = await this.orm.bigquery.createQueryJob({
      query: sql,
      params: allParams,
    });
    await job.getQueryResults();
    const [metadata] = await job.getMetadata();
    const affectedRows = Number(
      metadata.statistics?.query?.numDmlAffectedRows || 0
    );
    this.orm.logger.info(
      `[Model:update] Updated ${affectedRows} records for ${this.name} in dataset ${dataset}`
    );
    return affectedRows;
  }

  static async destroy(
    dataset: string,
    options: DestroyOptions
  ): Promise<number> {
    this.orm.logger.info(
      `[Model:destroy] Deleting records for ${this.name} in dataset ${dataset}`,
      {
        options,
      }
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[Model:destroy] Free tier mode: DESTROY (DELETE) not allowed."
      );
      throw new Error("Free tier mode: DESTROY (DELETE) not allowed.");
    }
    const { clause, params } = buildWhereClause(options.where);
    const sql = `DELETE FROM \`${dataset}.${this.tableName}\` WHERE ${
      clause || "TRUE"
    }`;

    this.orm.logger.info(
      `[Model:destroy] Executing query: ${sql} in dataset ${dataset}`,
      { params }
    );
    try {
      const [job] = await this.orm.bigquery.createQueryJob({
        query: sql,
        params,
      });
      await job.getQueryResults();
      const [metadata] = await job.getMetadata();
      const affectedRows = Number(
        metadata.statistics?.query?.numDmlAffectedRows || 0
      );
      this.orm.logger.info(
        `[Model:destroy] Deleted ${affectedRows} records for ${this.name} in dataset ${dataset}`
      );
      return affectedRows;
    } catch (error: any) {
      this.orm.logger.error(
        `[Model:destroy] Failed to delete records for ${this.name} in dataset ${dataset}`,
        {
          error: error.message,
          stack: error.stack,
          sql,
          params,
        }
      );
      throw error;
    }
  }

  static async increment(
    dataset: string,
    fields: string | string[],
    options: { by?: number; where: WhereOptions }
  ): Promise<number> {
    this.orm.logger.info(
      `[Model:increment] Incrementing fields for ${this.name} in dataset ${dataset}`,
      { fields, options }
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[Model:increment] Free tier mode: INCREMENT (UPDATE) not allowed."
      );
      throw new Error("Free tier mode: INCREMENT (UPDATE) not allowed.");
    }
    const by = options.by || 1;
    const fieldArray = Array.isArray(fields) ? fields : [fields];
    const setClauses = fieldArray
      .map((field) => `\`${field}\` = \`${field}\` + ${by}`)
      .join(", ");
    const { clause: whereClause, params: whereValues } = buildWhereClause(
      options.where
    );
    const sql = `UPDATE \`${dataset}.${
      this.tableName
    }\` SET ${setClauses} WHERE ${whereClause || "TRUE"}`;
    const [job] = await this.orm.bigquery.createQueryJob({
      query: sql,
      params: whereValues,
    });
    await job.getQueryResults();
    const [metadata] = await job.getMetadata();
    const affectedRows = Number(
      metadata.statistics?.query?.numDmlAffectedRows || 0
    );
    this.orm.logger.info(
      `[Model:increment] Incremented ${affectedRows} records for ${this.name} in dataset ${dataset}`
    );
    return affectedRows;
  }

  static async decrement(
    dataset: string,
    fields: string | string[],
    options: { by?: number; where: WhereOptions }
  ): Promise<number> {
    this.orm.logger.info(
      `[Model:decrement] Decrementing fields for ${this.name} in dataset ${dataset}`,
      { fields, options }
    );
    return this.increment(dataset, fields, {
      ...options,
      by: -(options.by || 1),
    });
  }

  static async truncate(dataset: string): Promise<void> {
    this.orm.logger.info(
      `[Model:truncate] Truncating table for ${this.name} in dataset ${dataset}`
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[Model:truncate] Free tier mode: TRUNCATE not allowed."
      );
      throw new Error("Free tier mode: TRUNCATE not allowed.");
    }
    const sql = `TRUNCATE TABLE \`${dataset}.${this.tableName}\``;
    await this.orm.bigquery.query(sql);
    this.orm.logger.info(
      `[Model:truncate] Table truncated for ${this.name} in dataset ${dataset}`
    );
  }

  static async describe(): Promise<Record<string, DataType>> {
    this.orm.logger.info(`[Model:describe] Describing table for ${this.name}`);
    return { ...this.attributes };
  }

  private static buildSelectQuery(
    dataset: string,
    options: FindOptions,
    selectOverride?: string
  ): { sql: string; params: Record<string, any> } {
    this.orm.logger.info(
      `[Model:buildSelectQuery] Building query for ${this.name} in dataset ${dataset}`,
      { options, selectOverride }
    );
    const mainAlias = this.tableName;
    let sql = `FROM \`${dataset}.${this.tableName}\` AS \`${mainAlias}\``;
    const params: Record<string, any> = {};
    const whereClauses: string[] = [];

    if (options.include) {
      for (const inc of options.include) {
        const as = inc.as || inc.model.tableName;
        const assoc = Object.values(this.associations).find(
          (a) => a.as === as && a.target === inc.model
        );
        if (!assoc) {
          this.orm.logger.error(
            `[Model:buildSelectQuery] Association not found for ${inc.model.name} in ${this.name}`
          );
          throw new Error(`Association not found for ${inc.model.name}`);
        }
        const joinType = inc.required ? "INNER JOIN" : "LEFT OUTER JOIN";
        let joinOn: string;
        if (assoc.type === "belongsTo") {
          joinOn = `\`${mainAlias}\`.\`${assoc.foreignKey}\` = \`${as}\`.\`${inc.model.primaryKey}\``;
          sql += ` ${joinType} \`${dataset}.${inc.model.tableName}\` AS \`${as}\` ON ${joinOn}`;
        } else if (assoc.type === "hasOne" || assoc.type === "hasMany") {
          joinOn = `\`${mainAlias}\`.\`${this.primaryKey}\` = \`${as}\`.\`${assoc.foreignKey}\``;
          sql += ` ${joinType} \`${dataset}.${inc.model.tableName}\` AS \`${as}\` ON ${joinOn}`;
        } else if (assoc.type === "belongsToMany") {
          if (!assoc.through || !assoc.otherKey) {
            this.orm.logger.error(
              `[Model:buildSelectQuery] Through model and otherKey required for belongsToMany in ${this.name}`
            );
            throw new Error(
              "Through model and otherKey required for belongsToMany"
            );
          }
          const throughAs = `${as}_through`;
          const throughTable = assoc.through.tableName;
          sql += ` ${joinType} \`${dataset}.${throughTable}\` AS \`${throughAs}\` ON \`${mainAlias}\`.\`${this.primaryKey}\` = \`${throughAs}\`.\`${assoc.foreignKey}\``;
          joinOn = `\`${throughAs}\`.\`${assoc.otherKey}\` = \`${as}\`.\`${inc.model.primaryKey}\``;
          sql += ` ${joinType} \`${dataset}.${inc.model.tableName}\` AS \`${as}\` ON ${joinOn}`;
        }

        if (inc.where) {
          const { clause, params: incParams } = buildWhereClause(inc.where);
          const prefixedClause = clause.replace(/`([^`]+)`/g, `\`${as}\`.$1`);
          whereClauses.push(prefixedClause);
          Object.assign(params, incParams);
        }
      }
    }

    let mainWhere = "";
    if (options.where) {
      const { clause, params: mParams } = buildWhereClause(options.where);
      mainWhere = clause;
      Object.assign(params, mParams);
    }

    let whereClause = [mainWhere, ...whereClauses]
      .filter((c) => c)
      .join(" AND ");
    if (whereClause) {
      sql += ` WHERE ${whereClause}`;
    }

    let selectClause: string[] = [];
    if (selectOverride) {
      selectClause.push(selectOverride);
    } else {
      const mainAttributes = options.attributes || Object.keys(this.attributes);
      for (const field of mainAttributes) {
        selectClause.push(
          `\`${mainAlias}\`.\`${field}\` AS \`${mainAlias}_${field}\``
        );
      }
      if (options.include) {
        for (const inc of options.include) {
          const as = inc.as || inc.model.tableName;
          const incAttributes =
            inc.attributes || Object.keys(inc.model.attributes);
          for (const field of incAttributes) {
            selectClause.push(`\`${as}\`.\`${field}\` AS \`${as}_${field}\``);
          }
        }
      }
    }

    if (options.distinct) {
      sql = `SELECT DISTINCT ${selectClause.join(", ")} ${sql}`;
    } else {
      sql = `SELECT ${selectClause.join(", ")} ${sql}`;
    }

    if (options.group) {
      sql += ` GROUP BY ${options.group.map((g) => `\`${g}\``).join(", ")}`;
    }

    if (options.order) {
      sql += ` ORDER BY ${options.order
        .map(([field, dir]) => `\`${field}\` ${dir}`)
        .join(", ")}`;
    }

    if (options.limit) {
      sql += ` LIMIT ${options.limit}`;
    }
    if (options.offset) {
      sql += ` OFFSET ${options.offset}`;
    }

    this.orm.logger.info(
      `[Model:buildSelectQuery] Generated SQL for ${this.name} in dataset ${dataset}`,
      { sql, params }
    );
    return { sql, params };
  }

  private static nestAssociations(
    rows: any[],
    includes: IncludeOptions[]
  ): any[] {
    this.orm.logger.info(
      `[Model:nestAssociations] Nesting associations for ${this.name}`,
      { includes }
    );
    if (!includes.length) {
      return rows.map((row) => {
        const result: any = {};
        for (const [key, value] of Object.entries(row)) {
          if (key.startsWith(`${this.tableName}_`)) {
            result[key.replace(`${this.tableName}_`, "")] = value;
          }
        }
        return result;
      });
    }

    const parentMap = new Map<any, any>();
    for (const row of rows) {
      const parentPKValue = row[`${this.tableName}_${this.primaryKey}`];
      if (parentPKValue == null) continue;

      let parent = parentMap.get(parentPKValue);
      if (!parent) {
        parent = {};
        for (const field in this.attributes) {
          parent[field] = row[`${this.tableName}_${field}`];
        }
        for (const inc of includes) {
          const as = inc.as || inc.model.tableName;
          const assoc = Object.values(this.associations).find(
            (a) => a.as === as
          );
          if (assoc) {
            if (assoc.type === "hasMany" || assoc.type === "belongsToMany") {
              parent[as] = [];
            } else {
              parent[as] = null;
            }
          }
        }
        parentMap.set(parentPKValue, parent);
      }

      for (const inc of includes) {
        const as = inc.as || inc.model.tableName;
        const assoc = Object.values(this.associations).find((a) => a.as === as);
        if (!assoc) continue;

        const childPK = row[`${as}_${inc.model.primaryKey}`];
        if (childPK == null) continue;

        const child: any = {};
        for (const field in inc.model.attributes) {
          child[field] = row[`${as}_${field}`];
        }

        if (assoc.type === "hasMany" || assoc.type === "belongsToMany") {
          if (
            !parent[as].some((c: any) => c[inc.model.primaryKey] === childPK)
          ) {
            parent[as].push(child);
          }
        } else {
          parent[as] = child;
        }
      }
    }

    const result = Array.from(parentMap.values());
    this.orm.logger.info(
      `[Model:nestAssociations] Nested ${result.length} records for ${this.name}`
    );
    return result;
  }
}


===== src\op.ts =====

// src/op.ts
export const Op = {
  eq: "=",
  ne: "!=",
  gt: ">",
  gte: ">=",
  lt: "<",
  lte: "<=",
  like: "LIKE",
  notLike: "NOT LIKE",
  in: "IN",
  notIn: "NOT IN",
  between: "BETWEEN",
  notBetween: "NOT BETWEEN",
  is: "IS",
  isNot: "IS NOT",
  and: "AND",
  or: "OR",
  not: "NOT",
  any: "ANY",
  all: "ALL",
  contains: "@>",
  contained: "<@",
  add: "+",
} as const;

export type Operator = keyof typeof Op;


===== src\queryInterface.ts =====

// src/queryInterface.ts
import { BigQuery } from "@google-cloud/bigquery";
import { BigQueryORM } from "./bigQueryORM";
import { DataType } from "./dataTypes";
import { dataTypeToSchemaField } from "./utils";

export class QueryInterface {
  QueryTypes = {
    SELECT: "SELECT",
    INSERT: "INSERT",
    UPDATE: "UPDATE",
    DELETE: "DELETE",
  };
  constructor(private orm: BigQueryORM) {}

  private dataTypeToString(type: DataType): string {
    this.orm.logger.info(
      "[QueryInterface:dataTypeToString] Converting data type to string",
      { type }
    );
    let base = "";
    if (type.type === "STRUCT") {
      base = `STRUCT<${Object.entries(type.fields || {})
        .map(([n, t]) => `\`${n}\` ${this.dataTypeToString(t)}`)
        .join(", ")}>`;
    } else if (["NUMERIC", "BIGNUMERIC", "DECIMAL"].includes(type.type)) {
      base = `${type.type}(${type.precision || 38}, ${type.scale || 9})`;
    } else {
      base = type.type;
    }

    if (type.mode === "REPEATED") {
      return `ARRAY<${base}>`;
    }
    return base;
  }

  async createTable(
    dataset: string,
    tableName: string,
    attributes: Record<string, DataType>,
    options: {
      partitionBy?: string;
      clusterBy?: string[];
      primaryKey?: string;
    } = {}
  ): Promise<void> {
    this.orm.logger.info("[QueryInterface:createTable] Starting createTable", {
      dataset,
      tableName,
      attributes: Object.keys(attributes),
      options,
    });
    if (this.orm.config.freeTierMode) {
      this.orm.logger.warn(
        "[QueryInterface:createTable] Free tier mode: Table creation counts toward 10GB storage limit."
      );
    }
    const ds = this.orm.bigquery.dataset(dataset);
    const [dsExists] = await ds.exists();
    if (!dsExists) {
      await ds.create();
      this.orm.logger.info(
        `[QueryInterface:createTable] Created dataset ${dataset}`
      );
    }
    const table = ds.table(tableName);
    const [tExists] = await table.exists();
    if (tExists) {
      this.orm.logger.info(
        `[QueryInterface:createTable] Table ${tableName} already exists in dataset ${dataset}, skipping creation`
      );
      return;
    }
    const schema = Object.entries(attributes).map(([name, type]) =>
      dataTypeToSchemaField(name, type)
    );
    const createOptions: any = { schema };
    if (options.partitionBy) {
      createOptions.timePartitioning = {
        type: "DAY",
        field: options.partitionBy,
      };
    }
    // Add clustering for primary key if provided (BigQuery's index equivalent)
    if (options.primaryKey) {
      createOptions.clustering = { fields: [options.primaryKey] };
      this.orm.logger.info(
        `[QueryInterface:createTable] Clustering table ${tableName} by primary key ${options.primaryKey} in dataset ${dataset}`
      );
    } else if (options.clusterBy) {
      createOptions.clustering = { fields: options.clusterBy };
    }
    await table.create(createOptions);
    this.orm.logger.info(
      `[QueryInterface:createTable] Created table ${tableName} in dataset ${dataset}`
    );
  }

  async dropTable(dataset: string, tableName: string): Promise<void> {
    this.orm.logger.info("[QueryInterface:dropTable] Starting dropTable", {
      dataset,
      tableName,
    });
    if (this.orm.config.freeTierMode) {
      this.orm.logger.warn(
        "[QueryInterface:dropTable] Free tier mode: Table deletion counts toward storage changes."
      );
    }
    const table = this.orm.bigquery.dataset(dataset).table(tableName);
    const [exists] = await table.exists();
    if (!exists) {
      this.orm.logger.info(
        `[QueryInterface:dropTable] Table ${tableName} does not exist in dataset ${dataset}, skipping deletion`
      );
      return;
    }
    await table.delete();
    this.orm.logger.info(
      `[QueryInterface:dropTable] Deleted table ${tableName} in dataset ${dataset}`
    );
  }

  async addColumn(
    dataset: string,
    tableName: string,
    columnName: string,
    type: DataType
  ): Promise<void> {
    this.orm.logger.info("[QueryInterface:addColumn] Starting addColumn", {
      dataset,
      tableName,
      columnName,
      type,
    });
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[QueryInterface:addColumn] Free tier mode: ADD COLUMN (DML) not allowed."
      );
      throw new Error("Free tier mode: ADD COLUMN (DML) not allowed.");
    }
    const dataTypeStr = this.dataTypeToString(type);
    const notNull = type.allowNull === false ? " NOT NULL" : "";
    const sql = `ALTER TABLE \`${this.orm.config.projectId}.${dataset}.${tableName}\` ADD COLUMN \`${columnName}\` ${dataTypeStr}${notNull}`;
    await this.orm.bigquery.query(sql);
    this.orm.logger.info(
      `[QueryInterface:addColumn] Added column ${columnName} to ${tableName} in dataset ${dataset}`
    );
  }

  async removeColumn(
    dataset: string,
    tableName: string,
    columnName: string
  ): Promise<void> {
    this.orm.logger.info(
      "[QueryInterface:removeColumn] Starting removeColumn",
      { dataset, tableName, columnName }
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[QueryInterface:removeColumn] Free tier mode: DROP COLUMN (DML) not allowed."
      );
      throw new Error("Free tier mode: DROP COLUMN (DML) not allowed.");
    }
    const sql = `ALTER TABLE \`${this.orm.config.projectId}.${dataset}.${tableName}\` DROP COLUMN IF EXISTS \`${columnName}\``;
    await this.orm.bigquery.query(sql);
    this.orm.logger.info(
      `[QueryInterface:removeColumn] Removed column ${columnName} from ${tableName} in dataset ${dataset}`
    );
  }

  async renameColumn(
    dataset: string,
    tableName: string,
    oldColumnName: string,
    newColumnName: string
  ): Promise<void> {
    this.orm.logger.info(
      "[QueryInterface:renameColumn] Starting renameColumn",
      { dataset, tableName, oldColumnName, newColumnName }
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[QueryInterface:renameColumn] Free tier mode: RENAME COLUMN (DML) not allowed."
      );
      throw new Error("Free tier mode: RENAME COLUMN (DML) not allowed.");
    }
    const sql = `ALTER TABLE \`${this.orm.config.projectId}.${dataset}.${tableName}\` RENAME COLUMN \`${oldColumnName}\` TO \`${newColumnName}\``;
    await this.orm.bigquery.query(sql);
    this.orm.logger.info(
      `[QueryInterface:renameColumn] Renamed column ${oldColumnName} to ${newColumnName} in ${tableName} in dataset ${dataset}`
    );
  }

  async changeColumn(
    dataset: string,
    tableName: string,
    columnName: string,
    type: DataType
  ): Promise<void> {
    this.orm.logger.info(
      "[QueryInterface:changeColumn] Starting changeColumn",
      { dataset, tableName, columnName, type }
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[QueryInterface:changeColumn] Free tier mode: ALTER COLUMN (DML) not allowed."
      );
      throw new Error("Free tier mode: ALTER COLUMN (DML) not allowed.");
    }
    const dataTypeStr = this.dataTypeToString(type);
    const sql = `ALTER TABLE \`${this.orm.config.projectId}.${dataset}.${tableName}\` ALTER COLUMN \`${columnName}\` SET DATA TYPE ${dataTypeStr}`;
    await this.orm.bigquery.query(sql);
    this.orm.logger.info(
      `[QueryInterface:changeColumn] Changed column ${columnName} type in ${tableName} in dataset ${dataset}`
    );
  }

  async addPartition(
    dataset: string,
    tableName: string,
    partitionBy: string
  ): Promise<void> {
    this.orm.logger.info(
      "[QueryInterface:addPartition] Starting addPartition",
      { dataset, tableName, partitionBy }
    );
    this.orm.logger.warn(
      "[QueryInterface:addPartition] Partitioning requires table recreation."
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.error(
        "[QueryInterface:addPartition] Free tier mode: Partition changes not supported."
      );
      throw new Error("Free tier mode: Partition changes not supported.");
    }
    // Note: BigQuery requires table recreation for partitioning changes
    this.orm.logger.info(
      "[QueryInterface:addPartition] Partitioning not directly supported; manual table recreation required."
    );
  }

  async addClustering(
    dataset: string,
    tableName: string,
    clusterBy: string[]
  ): Promise<void> {
    this.orm.logger.info(
      "[QueryInterface:addClustering] Starting addClustering",
      { dataset, tableName, clusterBy }
    );
    if (this.orm.config.freeTierMode) {
      this.orm.logger.warn(
        "[QueryInterface:addClustering] Free tier mode: Clustering may incur query costs."
      );
    }
    const sql = `ALTER TABLE \`${
      this.orm.config.projectId
    }.${dataset}.${tableName}\` SET OPTIONS (clustering_fields = '${JSON.stringify(
      clusterBy
    )}')`;
    await this.orm.bigquery.query(sql);
    this.orm.logger.info(
      `[QueryInterface:addClustering] Added clustering to ${tableName} in dataset ${dataset}`
    );
  }

  async query(dataset: string, sql: string, params?: any): Promise<any> {
    this.orm.logger.info("[QueryInterface:query] Starting query execution", {
      dataset,
      sql,
      params,
    });
    if (
      this.orm.config.freeTierMode &&
      sql.trim().toUpperCase().startsWith("INSERT")
    ) {
      this.orm.logger.error(
        "[QueryInterface:query] Free tier mode: INSERT queries not allowed."
      );
      throw new Error("Free tier mode: INSERT queries not allowed.");
    }
    const result = await this.orm.bigquery.query({ query: sql, params });
    this.orm.logger.info(
      `[QueryInterface:query] Executed query successfully for dataset ${dataset}`
    );
    return result;
  }
}


===== src\utils.ts =====

// src/utils.ts
import { DataType } from "./dataTypes";
import { Op, Operator } from "./op";

export function dataTypeToSchemaField(name: string, dt: DataType): any {
  let mode = dt.allowNull === false ? "REQUIRED" : "NULLABLE";
  if (dt.mode === "REPEATED") {
    mode = "REPEATED";
  }

  let type = dt.type;
  if (type === "STRUCT") {
    type = "STRUCT"; // or "RECORD"
    return {
      name,
      type,
      mode,
      fields: Object.entries(dt.fields || {}).map(([fieldName, fieldType]) =>
        dataTypeToSchemaField(fieldName, fieldType)
      ),
    };
  } else if (["NUMERIC", "BIGNUMERIC", "DECIMAL"].includes(type)) {
    return {
      name,
      type,
      mode,
      precision: dt.precision,
      scale: dt.scale,
    };
  } else {
    return { name, type, mode };
  }
}

export function buildWhereClause(
  where: any,
  params: Record<string, any> = {},
  paramIndex = 0
): { clause: string; params: Record<string, any>; nextIndex: number } {
  if (!where) return { clause: "", params: {}, nextIndex: paramIndex };

  const clauses: string[] = [];
  const localParams: Record<string, any> = {};

  for (const [key, value] of Object.entries(where)) {
    if (key === "and" || key === "or") {
      const subResults = (value as any[]).reduce(
        (acc, subCondition) => {
          const {
            clause,
            params: subParams,
            nextIndex,
          } = buildWhereClause(subCondition, acc.paramsAcc, acc.indexAcc);
          return {
            clauseAcc: [...acc.clauseAcc, `(${clause})`],
            paramsAcc: { ...acc.paramsAcc, ...subParams },
            indexAcc: nextIndex,
          };
        },
        {
          clauseAcc: [] as string[],
          paramsAcc: {} as Record<string, any>,
          indexAcc: paramIndex,
        }
      );
      clauses.push(subResults.clauseAcc.join(` ${Op[key as Operator]} `));
      Object.assign(localParams, subResults.paramsAcc);
      paramIndex = subResults.indexAcc;
    } else if (Array.isArray(value)) {
      const paramNames = value
        .map((v) => {
          const paramName = `param${paramIndex++}`;
          localParams[paramName] = v;
          return `@${paramName}`;
        })
        .join(", ");
      clauses.push(`\`${key}\` IN (${paramNames})`);
    } else if (
      typeof value === "object" &&
      value !== null &&
      !Array.isArray(value)
    ) {
      const opKey = Object.keys(value)[0] as Operator;
      const opVal = value[opKey as keyof typeof value];
      const sqlOp = Op[opKey] || "=";
      const paramName = `param${paramIndex++}`;
      clauses.push(`\`${key}\` ${sqlOp} @${paramName}`);
      localParams[paramName] = opVal;
    } else {
      const paramName = `param${paramIndex++}`;
      clauses.push(`\`${key}\` = @${paramName}`);
      localParams[paramName] = value;
    }
  }

  return {
    clause: clauses.join(" AND "),
    params: localParams,
    nextIndex: paramIndex,
  };
}
